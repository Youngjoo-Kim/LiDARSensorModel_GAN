{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os,random\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "#os.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d,lib.cnmem=0\"%(random.randint(0,3))\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers import Input,merge, Conv2D\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.regularizers import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle, random, sys, keras\n",
    "from keras.models import Model\n",
    "from IPython import display\n",
    "\n",
    "sys.path.append(\"../common\")\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lidar_path = '../../../../research_data/datasets/kitti/kitti-yolo-100m-res-0.1/npy'\n",
    "data = np.load(lidar_path + '/outfile_9999.npy')\n",
    "import os\n",
    "\n",
    "'''\n",
    "for root, dirs, files in os.walk(lidar_path):\n",
    "    for file in files:        \n",
    "        if file.endswith((\".npy\")):\n",
    "            print file\n",
    "'''\n",
    "\n",
    "files = sorted(os.listdir(lidar_path))\n",
    "lidar_data = []\n",
    "i = 0\n",
    "for file in files:\n",
    "    if file.endswith((\".npy\")):\n",
    "        data = np.load(lidar_path + '/' + file)\n",
    "        data = data.astype(np.float64)\n",
    "        lidar_data.append(data)\n",
    "        i+=1\n",
    "        if(i==data_len):\n",
    "            break\n",
    "lidar_data = np.array(lidar_data)        \n",
    "# Add the channel dim\n",
    "lidar_data = np.expand_dims(lidar_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lidar_data[5,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "path_to_file = '../../../../research_data/datasets/kitti/rgb_images'\n",
    "img = '5.png'\n",
    "plt.imshow(mpimg.imread(path_to_file + '/' + img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = mpimg.imread(path_to_file + '/' + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from PIL import Image\n",
    "path_to_file = '../../../datasets/kitti/rgb_images'\n",
    "im_frame = Image.open(path_to_file + '/0.png')\n",
    "np_frame = np.array(im_frame.getdata())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "camera_path = '../../../../research_data/datasets/kitti/rgb_images'\n",
    "files = sorted(os.listdir(camera_path))\n",
    "camera_data = []\n",
    "i = 0\n",
    "for file in files:\n",
    "    if file.endswith((\".png\")):        \n",
    "        #im_frame = Image.open(camera_path + '/' + file)\n",
    "        im_frame = mpimg.imread(camera_path + '/' + file)\n",
    "        im_frame /= 255\n",
    "        camera_data.append(im_frame)\n",
    "        i+=1\n",
    "        if(i==data_len):\n",
    "            break\n",
    "camera_data = np.array(camera_data) \n",
    "# Make channel first\n",
    "camera_data = np.array(np.transpose(camera_data, (0, 3, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "# Build Generative model ...\n",
    "nch = 2\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = lidar_data.shape[1:]\n",
    "flat_img_size = camera_data.shape[1]*camera_data.shape[2]*camera_data.shape[3]\n",
    "g_input = Input(shape=[flat_img_size])\n",
    "#g_input = Input(shape=camera_data.shape[1:])\n",
    "#H = Flatten()(g_input)\n",
    "#H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(H)\n",
    "H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(g_input)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [nch, lidar_img_L/2, lidar_img_W/2] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(nch/4, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "# Build Generative model ...\n",
    "nch = 2\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = lidar_data.shape[1:]\n",
    "flat_img_size = camera_data.shape[1]*camera_data.shape[2]*camera_data.shape[3]\n",
    "#g_input = Input(shape=[flat_img_size])\n",
    "g_input = Input(shape=camera_data.shape[1:])\n",
    "print(g_input.shape)\n",
    "H = Flatten()(g_input)\n",
    "print(H.shape)\n",
    "#H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(H)\n",
    "H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(g_input)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [nch, lidar_img_L/2, lidar_img_W/2] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(nch/4, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# First, define the vision modules\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "print(x.shape)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "out = Reshape( [11, 11, 64] )(out)\n",
    "print(out.shape)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "print(vision_model.summary())\n",
    "\n",
    "# Then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)\n",
    "print(classification_model.summary())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "# Build Generative model ...\n",
    "nch = 4\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = lidar_data.shape[1:]\n",
    "flat_img_size = camera_data.shape[1]*camera_data.shape[2]*camera_data.shape[3]\n",
    "\n",
    "\n",
    "g_input = Input(shape=camera_data.shape[1:])\n",
    "print(g_input.shape)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(g_input)\n",
    "print(H.shape)\n",
    "H = Flatten()(H)\n",
    "print(H.shape)\n",
    "H = Dense(lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [1, lidar_img_L/2, lidar_img_W/2] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(nch/4, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "# Build Generative model ...\n",
    "nch = 4\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = lidar_data.shape[1:]\n",
    "flat_img_size = camera_data.shape[1]*camera_data.shape[2]*camera_data.shape[3]\n",
    "\n",
    "\n",
    "g_input = Input(shape=camera_data.shape[1:])\n",
    "#Encoder\n",
    "H = Conv2D(nch, (3, 3), data_format='channels_first', border_mode='valid', init='glorot_uniform')(g_input)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "\n",
    "# Decoder\n",
    "H = Flatten()(H)\n",
    "H = Dense(lidar_img_L/4*lidar_img_W/4, init='glorot_normal')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [1, lidar_img_L/4, lidar_img_W/4] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_img = np.reshape(camera_data[0:2], [2, flat_img_size])\n",
    "input_img = camera_data\n",
    "generated_lidar = generator.predict(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_lidar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both LiDAR and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "camera_data = list(camera_data)\n",
    "lidar_data = list(lidar_data)\n",
    "\n",
    "df = pd.DataFrame({'images':camera_data, 'lidar':lidar_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 42\n",
    "test_size = 0.1\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "(X_train, X_test) = train_test_split(df, test_size=test_size, random_state=random_state, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#shp = X_train.shape[1:]\n",
    "#print shp\n",
    "\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "#opt = Adam(lr=1e-3)\n",
    "#opt = Adamax(lr=1e-4)\n",
    "#opt = Adam(lr=0.0002)\n",
    "#opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "\n",
    "# Build Generative model ...\n",
    "nch = 20\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = df['lidar'][0].shape\n",
    "flat_img_size = df['images'][0].shape[0]*df['images'][0].shape[1]*df['images'][0].shape[2]\n",
    "g_input = Input(shape=[flat_img_size])\n",
    "#H = Flatten()(g_input)\n",
    "#H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(H)\n",
    "H = Dense(nch*lidar_img_L/2*lidar_img_W/2, init='glorot_normal')(g_input)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [nch, lidar_img_L/2, lidar_img_W/2] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(nch/4, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "# Build Discriminative model ...\n",
    "d_input = Input(shape=df['lidar'][0].shape)\n",
    "#d_input = Input(shape=(1, df['lidar'][0].shape[0], df['lidar'][0].shape[1]))\n",
    "\n",
    "#H = keras.backend.expand_dims(d_input, axis=1)\n",
    "#print(H.shape)\n",
    "H = Conv2D(256, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(d_input)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Conv2D(512, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Flatten()(H)\n",
    "H = Dense(256)(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "d_V = Dense(2,activation='softmax')(H)\n",
    "discriminator = Model(d_input,d_V)\n",
    "discriminator.compile(loss='categorical_crossentropy', optimizer=dopt)\n",
    "discriminator.summary()\n",
    "\n",
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "make_trainable(discriminator, False)\n",
    "# Build stacked GAN model\n",
    "#gan_input = Input(shape=df['images'][0].shape)\n",
    "gan_input = Input(shape=[flat_img_size])\n",
    "H = generator(gan_input)\n",
    "gan_V = discriminator(H)\n",
    "GAN = Model(gan_input, gan_V)\n",
    "GAN.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "GAN.summary()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dropout_rate = 0.25\n",
    "# Optim\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "dopt = Adam(lr=1e-4)\n",
    "# Build Generative model ...\n",
    "nch = 4\n",
    "#(img_L, img_W) = df['images'][0].shape\n",
    "(ch, lidar_img_L, lidar_img_W) = df['lidar'][0].shape\n",
    "\n",
    "g_input = Input(shape=df['images'][0].shape)\n",
    "#Encoder\n",
    "H = Conv2D(nch, (3, 3), data_format='channels_first', subsample=(2, 2), border_mode='valid', init='glorot_uniform')(g_input)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', subsample=(2, 2), border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', subsample=(2, 2), border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', subsample=(2, 2), border_mode='valid', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "\n",
    "# Decoder\n",
    "H = Flatten()(H)\n",
    "H = Dense(lidar_img_L/4*lidar_img_W/4, init='glorot_normal')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape( [1, lidar_img_L/4, lidar_img_W/4] )(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch/2, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = UpSampling2D(size=(2, 2), data_format='channels_first')(H)\n",
    "H = Conv2D(nch, (3, 3), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Conv2D(1, (1, 1), data_format='channels_first', border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input,g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "# Build Discriminative model ...\n",
    "d_input = Input(shape=df['lidar'][0].shape)\n",
    "#d_input = Input(shape=(1, df['lidar'][0].shape[0], df['lidar'][0].shape[1]))\n",
    "\n",
    "#H = keras.backend.expand_dims(d_input, axis=1)\n",
    "#print(H.shape)\n",
    "H = Conv2D(8, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(d_input)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Conv2D(8, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Conv2D(8, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Conv2D(256, (5, 5), data_format='channels_first', subsample=(2, 2), border_mode = 'same', activation='relu')(H)\n",
    "H = MaxPooling2D((2,2), data_format='channels_first', border_mode='valid')(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "H = Flatten()(H)\n",
    "H = Dense(256)(H)\n",
    "H = LeakyReLU(0.2)(H)\n",
    "H = Dropout(dropout_rate)(H)\n",
    "d_V = Dense(2,activation='softmax')(H)\n",
    "discriminator = Model(d_input,d_V)\n",
    "discriminator.compile(loss='categorical_crossentropy', optimizer=dopt)\n",
    "discriminator.summary()\n",
    "\n",
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "make_trainable(discriminator, False)\n",
    "# Build stacked GAN model\n",
    "gan_input = Input(shape=df['images'][0].shape)\n",
    "#gan_input = Input(shape=[flat_img_size])\n",
    "H = generator(gan_input)\n",
    "gan_V = discriminator(H)\n",
    "GAN = Model(gan_input, gan_V)\n",
    "GAN.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "GAN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gen(img, n_ex=16,dim=(4,4), figsize=(10,10) ):\n",
    "    \n",
    "    generated_lidar = generator.predict(img)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_lidar.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_lidar[i,0,:,:]\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_imgs = np.stack(np.array(X_train['images']).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#images_gen = np.reshape(train_imgs, [train_imgs.shape[0], train_imgs.shape[1]*train_imgs.shape[2]*train_imgs.shape[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ntrain = 900\n",
    "#trainidx = random.sample(range(0,X_train.shape[0]), ntrain)\n",
    "#XT = X_train\n",
    "\n",
    "# Pre-train the discriminator network ...\n",
    "#noise_gen = np.random.uniform(0,1,size=[XT.shape[0],100])\n",
    "BATCH_SIZE = 2\n",
    "n_epochs = 10\n",
    "#XT = X_train.sample(n=BATCH_SIZE, random_state=random_state)\n",
    "#print(XT.shape)\n",
    "train_imgs = np.stack(np.array(X_train['images']).flat)\n",
    "#images_gen = np.array(np.transpose(train_imgs, (0, 3, 1, 2)))\n",
    "\n",
    "#images_gen = np.reshape(train_imgs, [train_imgs.shape[0], train_imgs.shape[1]*train_imgs.shape[2]*train_imgs.shape[3]])\n",
    "images_gen = train_imgs\n",
    "#print(images_gen.shape)\n",
    "train_lidar = np.stack(np.array(X_train['lidar']).flat)\n",
    "#train_lidar = np.expand_dims(train_lidar, axis=1)\n",
    "#generator.fit(images_gen, train_lidar, nb_epoch=100, batch_size=BATCH_SIZE)\n",
    "generated_lidar = generator.predict(images_gen)\n",
    "\n",
    "#print(train_lidar.shape)\n",
    "X = np.concatenate((train_lidar, generated_lidar))\n",
    "n = X_train.shape[0]\n",
    "y = np.zeros([2*n,2])\n",
    "y[:n,1] = 1\n",
    "y[n:,0] = 1\n",
    "\n",
    "make_trainable(discriminator,True)\n",
    "discriminator.fit(X,y, nb_epoch=n_epochs, batch_size=BATCH_SIZE)\n",
    "y_hat = discriminator.predict(X)\n",
    "make_trainable(discriminator,False)\n",
    "y2 = np.zeros([len(images_gen),2])\n",
    "y2[:,1] = 1\n",
    "GAN.fit(images_gen, y2,nb_epoch=n_epochs, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_idx = np.argmax(y_hat,axis=1)\n",
    "y_idx = np.argmax(y,axis=1)\n",
    "diff = y_idx-y_hat_idx\n",
    "n_tot = y.shape[0]\n",
    "n_rig = (diff==0).sum()\n",
    "acc = n_rig*100.0/n_tot\n",
    "print \"Accuracy: %0.02f pct (%d of %d) right\"%(acc, n_rig, n_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up loss storage vector\n",
    "losses = {\"d\":[], \"g\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_trainable(discriminator,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_for_n(nb_epoch=5000, plt_frq=25,BATCH_SIZE=32):\n",
    "\n",
    "    for e in tqdm(range(nb_epoch)):  \n",
    "        \n",
    "        # Make generative images\n",
    "        #XT = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE)]    \n",
    "        XT = X_train.sample(n=BATCH_SIZE, random_state=random_state)\n",
    "        #lidar_batch = np.array(XT['lidar'])\n",
    "        train_lidar = np.stack(np.array(XT['lidar']).flat)\n",
    "        #noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        #images_gen = np.array(XT['images'])\n",
    "        train_imgs = np.stack(np.array(XT['images']).flat)\n",
    "        #images_gen = np.array(np.transpose(train_imgs, (0, 3, 1, 2)))# Channels first\n",
    "        #generator.train_on_batch(images_gen, train_lidar, nb_epoch=100, batch_size=BATCH_SIZE)\n",
    "    \n",
    "        generated_lidar = generator.predict(train_imgs)\n",
    "\n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((train_lidar, generated_lidar))\n",
    "        y = np.zeros([2*BATCH_SIZE,2])\n",
    "        y[0:BATCH_SIZE,1] = 1\n",
    "        y[BATCH_SIZE:,0] = 1\n",
    "        \n",
    "        make_trainable(discriminator,True)\n",
    "        d_loss  = discriminator.train_on_batch(X,y)\n",
    "        losses[\"d\"].append(d_loss)\n",
    "    \n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        #noise_tr = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        y2 = np.zeros([BATCH_SIZE,2])\n",
    "        y2[:,1] = 1\n",
    "        \n",
    "        make_trainable(discriminator,False)\n",
    "        g_loss = GAN.train_on_batch(train_imgs, y2 )\n",
    "        losses[\"g\"].append(g_loss)\n",
    "        \n",
    "        # Updates plots\n",
    "        if e%plt_frq==plt_frq-1:\n",
    "            plot_loss(losses)\n",
    "            plot_gen(train_imgs[0:2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_for_n(nb_epoch=6000, plt_frq=25,BATCH_SIZE=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.lr= 1e-5\n",
    "dopt.lr = 1e-4\n",
    "train_for_n(nb_epoch=2000, plt_frq=25,BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.lr = 1e-6\n",
    "dopt.lr = 1e-5\n",
    "train_for_n(nb_epoch=2000, plt_frq=25,BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_gen(25,(5,5),(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_real(n_ex=16,dim=(4,4), figsize=(10,10) ):\n",
    "    \n",
    "    idx = np.random.randint(0,X_train.shape[0],n_ex)\n",
    "    generated_images = X_train[idx,:,:,:]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,0,:,:]\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_real()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
